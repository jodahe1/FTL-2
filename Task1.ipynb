{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic data with different feature scales\n",
    "def generate_data():\n",
    "    np.random.seed(0)\n",
    "    temperature = 20 + 20 * np.random.rand(100, 1)  # Range [20, 40]\n",
    "    ice_cream_sales = 200 * np.random.rand(100, 1)  # Range [0, 200]\n",
    "    X = np.hstack((temperature, ice_cream_sales))\n",
    "    y = 1000 + 30 * temperature + 5 * ice_cream_sales + np.random.randn(100, 1)\n",
    "    return X, y\n",
    "\n",
    "# Feature scaling methods\n",
    "def max_scaling(X):\n",
    "    \"\"\"Scale features to [0, 1] range using max value\"\"\"\n",
    "    X_max = np.max(X, axis=0)\n",
    "    X_scaled = X / X_max\n",
    "    return X_scaled\n",
    "\n",
    "def mean_normalization(X):\n",
    "    \"\"\"Scale features to have mean=0 and range [-1, 1]\"\"\"\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_max = np.max(X, axis=0)\n",
    "    X_min = np.min(X, axis=0)\n",
    "    X_scaled = (X - X_mean) / (X_max - X_min)\n",
    "    return X_scaled\n",
    "\n",
    "def z_score_normalization(X):\n",
    "    \"\"\"Standardize features to have mean=0 and std=1\"\"\"\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_std = np.std(X, axis=0)\n",
    "    X_scaled = (X - X_mean) / X_std\n",
    "    return X_scaled\n",
    "\n",
    "# Linear regression functions\n",
    "def compute_cost(X, y, w, b):\n",
    "    \"\"\"Compute the mean squared error cost\"\"\"\n",
    "    m = len(X)\n",
    "    y_pred = np.dot(X, w) + b\n",
    "    cost = np.mean((y_pred - y) ** 2)\n",
    "    return cost\n",
    "\n",
    "def gradient_descent(X, y, w, b, alpha, num_iterations):\n",
    "    \"\"\"Perform gradient descent optimization\"\"\"\n",
    "    m = len(X)\n",
    "    cost_history = []\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        # Compute predictions\n",
    "        y_pred = np.dot(X, w) + b\n",
    "        \n",
    "        # Compute gradients\n",
    "        w_gradient = (1 / m) * np.dot(X.T, (y_pred - y))\n",
    "        b_gradient = (1 / m) * np.sum(y_pred - y)\n",
    "        \n",
    "        # Update weights and bias\n",
    "        w -= alpha * w_gradient.reshape(-1, 1)\n",
    "        b -= alpha * b_gradient\n",
    "        \n",
    "        # Store cost for plotting\n",
    "        cost = compute_cost(X, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "    return w, b, cost_history\n",
    "\n",
    "def train_and_evaluate(X_scaled, y, scaling_method_name):\n",
    "    \"\"\"Train model and evaluate performance\"\"\"\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize parameters\n",
    "    n_features = X_train.shape[1]\n",
    "    w = np.zeros((n_features, 1))\n",
    "    b = 0\n",
    "    alpha = 0.01\n",
    "    num_iterations = 1000\n",
    "    \n",
    "    # Train model\n",
    "    w, b, cost_history = gradient_descent(X_train, y_train, w, b, alpha, num_iterations)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = np.dot(X_test, w) + b\n",
    "    mse = np.mean((y_pred - y_test) ** 2)\n",
    "    \n",
    "    print(f\"\\nResults for {scaling_method_name}:\")\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"Learned Coefficients (Weights):\")\n",
    "    print(w)\n",
    "    print(\"Bias (Intercept):\", b)\n",
    "    \n",
    "    # Plot cost history\n",
    "    plt.figure()\n",
    "    plt.plot(cost_history)\n",
    "    plt.title(f'Cost History - {scaling_method_name}')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.show()\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    X, y = generate_data()\n",
    "    \n",
    "    # Apply different scaling methods\n",
    "    scaling_methods = {\n",
    "        'Max Scaling': max_scaling,\n",
    "        'Mean Normalization': mean_normalization,\n",
    "        'Z-Score Normalization': z_score_normalization\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, method in scaling_methods.items():\n",
    "        X_scaled = method(X)\n",
    "        mse = train_and_evaluate(X_scaled, y, name)\n",
    "        results[name] = mse\n",
    "    \n",
    "    # Compare results\n",
    "    print(\"\\nComparison of Scaling Methods:\")\n",
    "    for name, mse in results.items():\n",
    "        print(f\"{name}: MSE = {mse:.2f}\")\n",
    "    \n",
    "    # Find best method\n",
    "    best_method = min(results, key=results.get)\n",
    "    print(f\"\\nBest performing method: {best_method} with MSE = {results[best_method]:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
